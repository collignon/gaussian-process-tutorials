{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The plot\n",
    "\n",
    "- Neural Nets are simple mathematical models defining a function.\n",
    "- A Neural Net with a fixed structure is characterized by the unit biases and connection weights parameters\n",
    "- Thus a prior over biases and weights implies a prior over functions.\n",
    "- However, the meaning of weights and biases in neural nets is obscure.\n",
    "- Moreover, the number of hidden units (in a multilayer perceptron with single hidden layer) limits the set of functions representable by the neural net.\n",
    "- By increasing the number of hidden units to infinity, and by selecting appropriate priors for the neural net parameters, the corresponding prior over functions is a Gaussian Process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background on Neural Nets\n",
    "- Mathematical formulation\n",
    "- Multilayer Perceptron\n",
    "- Representation of a single hidden-layer perceptron as a DAG, with labels for unit biases and connection weights\n",
    "- Mathematical expression for the corresponding perceptron with $\\tanh$ activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting priors on Neurals Nets\n",
    "- Everything is zero-mean Gaussian\n",
    "- The number of hidden units increases to infinity\n",
    "- Prove that the the joint distribution of the values of the function at any finite number of points is multivariate Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph for generating smooth functions with Neural Nets\n",
    "*Make it interactive, let the user pick the number of hidden units\n",
    "\n",
    "## Graph for generating smooth functions with Gaussian Processes\n",
    "*RBF kernel, similar to the GP_tutorial_one\n",
    "\n",
    "## Show the relationship between GP and Neural Net covariance for smooth functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra\n",
    "\n",
    "- Sample Brownian motion functions from a GP and from a NN (with increasing number of hidden units)\n",
    "- Show relationship between covariance functions\n",
    "\n",
    "# Possible extra\n",
    "\n",
    "- Talk about priors for networks with more than one hidden layers?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (whatever you want to call it)",
   "language": "python",
   "name": "envname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
